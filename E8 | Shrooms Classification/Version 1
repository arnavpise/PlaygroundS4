{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":76727,"databundleVersionId":9045607,"sourceType":"competition"}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn\nimport imblearn\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom torch.cuda.amp import GradScaler, autocast\nfrom scipy.sparse import csr_matrix\n\n# For categorical target, use Chi-square test\nfrom sklearn.feature_selection import chi2\nfrom sklearn.preprocessing import LabelEncoder\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-01T10:27:58.516919Z","iopub.execute_input":"2024-08-01T10:27:58.517982Z","iopub.status.idle":"2024-08-01T10:28:01.714986Z","shell.execute_reply.started":"2024-08-01T10:27:58.517946Z","shell.execute_reply":"2024-08-01T10:28:01.713933Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s4e8/sample_submission.csv\n/kaggle/input/playground-series-s4e8/train.csv\n/kaggle/input/playground-series-s4e8/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available else \"cpu\"\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:28:01.716850Z","iopub.execute_input":"2024-08-01T10:28:01.717512Z","iopub.status.idle":"2024-08-01T10:28:01.722396Z","shell.execute_reply.started":"2024-08-01T10:28:01.717477Z","shell.execute_reply":"2024-08-01T10:28:01.721440Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train = pd.read_csv(r'/kaggle/input/playground-series-s4e8/train.csv')\ndf_test = pd.read_csv(r'/kaggle/input/playground-series-s4e8/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:28:01.723604Z","iopub.execute_input":"2024-08-01T10:28:01.723945Z","iopub.status.idle":"2024-08-01T10:28:14.843565Z","shell.execute_reply.started":"2024-08-01T10:28:01.723912Z","shell.execute_reply":"2024-08-01T10:28:14.842516Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df_for_preds_id = pd.read_csv(r'/kaggle/input/playground-series-s4e8/test.csv')\ndf_for_preds_id.shape\n","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:59:39.429160Z","iopub.execute_input":"2024-08-01T10:59:39.429512Z","iopub.status.idle":"2024-08-01T10:59:44.195088Z","shell.execute_reply.started":"2024-08-01T10:59:39.429489Z","shell.execute_reply":"2024-08-01T10:59:44.194134Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"(2077964, 21)"},"metadata":{}}]},{"cell_type":"code","source":"print(df_train.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:28:14.846346Z","iopub.execute_input":"2024-08-01T10:28:14.847019Z","iopub.status.idle":"2024-08-01T10:28:19.101877Z","shell.execute_reply.started":"2024-08-01T10:28:14.846981Z","shell.execute_reply":"2024-08-01T10:28:19.100928Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"id                            0\nclass                         0\ncap-diameter                  4\ncap-shape                    40\ncap-surface              671023\ncap-color                    12\ndoes-bruise-or-bleed          8\ngill-attachment          523936\ngill-spacing            1258435\ngill-color                   57\nstem-height                   0\nstem-width                    0\nstem-root               2757023\nstem-surface            1980861\nstem-color                   38\nveil-type               2957493\nveil-color              2740947\nhas-ring                     24\nring-type                128880\nspore-print-color       2849682\nhabitat                      45\nseason                        0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"df_test","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:58:28.618716Z","iopub.execute_input":"2024-08-01T10:58:28.619537Z","iopub.status.idle":"2024-08-01T10:58:28.641787Z","shell.execute_reply.started":"2024-08-01T10:58:28.619502Z","shell.execute_reply":"2024-08-01T10:58:28.640535Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"              id  cap-diameter  cap-shape  cap-surface  cap-color  \\\n0              0           824         59           53         44   \n1              1           650         50           53         45   \n2              2           160         36           38         44   \n3              3           307         59           53         44   \n4              4           577         59           39         55   \n...          ...           ...        ...          ...        ...   \n2077959  2077959            48         59           38         53   \n2077960  2077960           272         59           50         53   \n2077961  2077961           533         59           36         34   \n2077962  2077962           463         36           38         44   \n2077963  2077963          1511         41           53         53   \n\n         does-bruise-or-bleed  gill-attachment  gill-spacing  gill-color  \\\n0                          18               37            17          52   \n1                           5               37            17          54   \n2                           5               37            17          41   \n3                           5               57            17          41   \n4                           5               55            17          54   \n...                       ...              ...           ...         ...   \n2077959                     5               37            18          52   \n2077960                     5               41            17          52   \n2077961                     5               37            17          52   \n2077962                     5               37            18          31   \n2077963                     5               41            17          54   \n\n         stem-height  stem-width  stem-color  has-ring  ring-type  habitat  \\\n0               1009        1669          51        17         15       16   \n1                 23        1032          38         6         14       16   \n2                514         271          38         6         14       16   \n3                394         808          51        17         35       16   \n4                569        1327          53        17         14       16   \n...              ...         ...         ...       ...        ...      ...   \n2077959          163          92          29         6         14       16   \n2077960          165         695          51         6         14       19   \n2077961          512         931          53        17         35       16   \n2077962          496         303          31         6         14       16   \n2077963          165        1728          51         6         14       16   \n\n         season  \n0             0  \n1             0  \n2             1  \n3             2  \n4             2  \n...         ...  \n2077959       2  \n2077960       0  \n2077961       0  \n2077962       0  \n2077963       3  \n\n[2077964 rows x 16 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cap-diameter</th>\n      <th>cap-shape</th>\n      <th>cap-surface</th>\n      <th>cap-color</th>\n      <th>does-bruise-or-bleed</th>\n      <th>gill-attachment</th>\n      <th>gill-spacing</th>\n      <th>gill-color</th>\n      <th>stem-height</th>\n      <th>stem-width</th>\n      <th>stem-color</th>\n      <th>has-ring</th>\n      <th>ring-type</th>\n      <th>habitat</th>\n      <th>season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>824</td>\n      <td>59</td>\n      <td>53</td>\n      <td>44</td>\n      <td>18</td>\n      <td>37</td>\n      <td>17</td>\n      <td>52</td>\n      <td>1009</td>\n      <td>1669</td>\n      <td>51</td>\n      <td>17</td>\n      <td>15</td>\n      <td>16</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>650</td>\n      <td>50</td>\n      <td>53</td>\n      <td>45</td>\n      <td>5</td>\n      <td>37</td>\n      <td>17</td>\n      <td>54</td>\n      <td>23</td>\n      <td>1032</td>\n      <td>38</td>\n      <td>6</td>\n      <td>14</td>\n      <td>16</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>160</td>\n      <td>36</td>\n      <td>38</td>\n      <td>44</td>\n      <td>5</td>\n      <td>37</td>\n      <td>17</td>\n      <td>41</td>\n      <td>514</td>\n      <td>271</td>\n      <td>38</td>\n      <td>6</td>\n      <td>14</td>\n      <td>16</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>307</td>\n      <td>59</td>\n      <td>53</td>\n      <td>44</td>\n      <td>5</td>\n      <td>57</td>\n      <td>17</td>\n      <td>41</td>\n      <td>394</td>\n      <td>808</td>\n      <td>51</td>\n      <td>17</td>\n      <td>35</td>\n      <td>16</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>577</td>\n      <td>59</td>\n      <td>39</td>\n      <td>55</td>\n      <td>5</td>\n      <td>55</td>\n      <td>17</td>\n      <td>54</td>\n      <td>569</td>\n      <td>1327</td>\n      <td>53</td>\n      <td>17</td>\n      <td>14</td>\n      <td>16</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2077959</th>\n      <td>2077959</td>\n      <td>48</td>\n      <td>59</td>\n      <td>38</td>\n      <td>53</td>\n      <td>5</td>\n      <td>37</td>\n      <td>18</td>\n      <td>52</td>\n      <td>163</td>\n      <td>92</td>\n      <td>29</td>\n      <td>6</td>\n      <td>14</td>\n      <td>16</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2077960</th>\n      <td>2077960</td>\n      <td>272</td>\n      <td>59</td>\n      <td>50</td>\n      <td>53</td>\n      <td>5</td>\n      <td>41</td>\n      <td>17</td>\n      <td>52</td>\n      <td>165</td>\n      <td>695</td>\n      <td>51</td>\n      <td>6</td>\n      <td>14</td>\n      <td>19</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2077961</th>\n      <td>2077961</td>\n      <td>533</td>\n      <td>59</td>\n      <td>36</td>\n      <td>34</td>\n      <td>5</td>\n      <td>37</td>\n      <td>17</td>\n      <td>52</td>\n      <td>512</td>\n      <td>931</td>\n      <td>53</td>\n      <td>17</td>\n      <td>35</td>\n      <td>16</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2077962</th>\n      <td>2077962</td>\n      <td>463</td>\n      <td>36</td>\n      <td>38</td>\n      <td>44</td>\n      <td>5</td>\n      <td>37</td>\n      <td>18</td>\n      <td>31</td>\n      <td>496</td>\n      <td>303</td>\n      <td>31</td>\n      <td>6</td>\n      <td>14</td>\n      <td>16</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2077963</th>\n      <td>2077963</td>\n      <td>1511</td>\n      <td>41</td>\n      <td>53</td>\n      <td>53</td>\n      <td>5</td>\n      <td>41</td>\n      <td>17</td>\n      <td>54</td>\n      <td>165</td>\n      <td>1728</td>\n      <td>51</td>\n      <td>6</td>\n      <td>14</td>\n      <td>16</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>2077964 rows × 16 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"missing_percentage = df_train.isnull().sum() / len(df_train) * 100\nprint(missing_percentage)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:28:19.102956Z","iopub.execute_input":"2024-08-01T10:28:19.103270Z","iopub.status.idle":"2024-08-01T10:28:23.349117Z","shell.execute_reply.started":"2024-08-01T10:28:19.103236Z","shell.execute_reply":"2024-08-01T10:28:23.348142Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"id                       0.000000\nclass                    0.000000\ncap-diameter             0.000128\ncap-shape                0.001283\ncap-surface             21.528227\ncap-color                0.000385\ndoes-bruise-or-bleed     0.000257\ngill-attachment         16.809280\ngill-spacing            40.373988\ngill-color               0.001829\nstem-height              0.000000\nstem-width               0.000000\nstem-root               88.452732\nstem-surface            63.551362\nstem-color               0.001219\nveil-type               94.884350\nveil-color              87.936970\nhas-ring                 0.000770\nring-type                4.134818\nspore-print-color       91.425482\nhabitat                  0.001444\nseason                   0.000000\ndtype: float64\n","output_type":"stream"}]},{"cell_type":"code","source":"missing_percentage = df_test.isnull().sum() / len(df_test) * 100\nprint(missing_percentage)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:28:23.350133Z","iopub.execute_input":"2024-08-01T10:28:23.350411Z","iopub.status.idle":"2024-08-01T10:28:25.977408Z","shell.execute_reply.started":"2024-08-01T10:28:23.350388Z","shell.execute_reply":"2024-08-01T10:28:25.976380Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"id                       0.000000\ncap-diameter             0.000337\ncap-shape                0.001492\ncap-surface             21.506821\ncap-color                0.000626\ndoes-bruise-or-bleed     0.000481\ngill-attachment         16.834796\ngill-spacing            40.404694\ngill-color               0.002358\nstem-height              0.000048\nstem-width               0.000000\nstem-root               88.452543\nstem-surface            63.595327\nstem-color               0.001011\nveil-type               94.878689\nveil-color              87.880445\nhas-ring                 0.000914\nring-type                4.148051\nspore-print-color       91.417224\nhabitat                  0.001203\nseason                   0.000000\ndtype: float64\n","output_type":"stream"}]},{"cell_type":"code","source":"# Calculate the threshold\nthreshold = 41\nmax_missing_count = len(df_train) * threshold\nprint(f\"Maximum missing values allowed: {max_missing_count}\")\n\n# Find columns exceeding the threshold\ncolumns_to_drop = missing_percentage[missing_percentage > threshold].index\nprint(f\"Features with too many missing values: {columns_to_drop}\")\n\ndf_train = df_train.drop(columns=columns_to_drop)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:28:25.978844Z","iopub.execute_input":"2024-08-01T10:28:25.979632Z","iopub.status.idle":"2024-08-01T10:28:26.586355Z","shell.execute_reply.started":"2024-08-01T10:28:25.979591Z","shell.execute_reply":"2024-08-01T10:28:26.585287Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Maximum missing values allowed: 127794745\nFeatures with too many missing values: Index(['stem-root', 'stem-surface', 'veil-type', 'veil-color',\n       'spore-print-color'],\n      dtype='object')\n","output_type":"stream"}]},{"cell_type":"code","source":"# Calculate the threshold\nthreshold = 41\nmax_missing_count = len(df_test) * threshold\nprint(f\"Maximum missing values allowed: {max_missing_count}\")\n\n# Find columns exceeding the threshold\ncolumns_to_drop = missing_percentage[missing_percentage > threshold].index\nprint(f\"Features with too many missing values: {columns_to_drop}\")\n\ndf_test = df_test.drop(columns=columns_to_drop)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:28:26.587538Z","iopub.execute_input":"2024-08-01T10:28:26.587829Z","iopub.status.idle":"2024-08-01T10:28:26.896566Z","shell.execute_reply.started":"2024-08-01T10:28:26.587804Z","shell.execute_reply":"2024-08-01T10:28:26.895585Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Maximum missing values allowed: 85196524\nFeatures with too many missing values: Index(['stem-root', 'stem-surface', 'veil-type', 'veil-color',\n       'spore-print-color'],\n      dtype='object')\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:28:26.897659Z","iopub.execute_input":"2024-08-01T10:28:26.897935Z","iopub.status.idle":"2024-08-01T10:28:30.528365Z","shell.execute_reply.started":"2024-08-01T10:28:26.897912Z","shell.execute_reply":"2024-08-01T10:28:30.527342Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"id                            0\nclass                         0\ncap-diameter                  4\ncap-shape                    40\ncap-surface              671023\ncap-color                    12\ndoes-bruise-or-bleed          8\ngill-attachment          523936\ngill-spacing            1258435\ngill-color                   57\nstem-height                   0\nstem-width                    0\nstem-color                   38\nhas-ring                     24\nring-type                128880\nhabitat                      45\nseason                        0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\n\n\ndf_train = pd.DataFrame(df_train)\ndf_test = pd.DataFrame(df_test)\n\n# Function to fill missing values with mode for each DataFrame\ndef fill_missing_with_mode(df_train, df_test):\n    # Calculate mode for each column in the training DataFrame\n    mode_values = df_train.mode().iloc[0]\n    \n    # Print mode values for reference\n    print(\"Mode values from training data:\")\n    print(mode_values)\n    \n    # Fill missing values in training data with mode values\n    df_train_filled = df_train.fillna(mode_values)\n    \n    # Fill missing values in testing data with mode values from training data\n    df_test_filled = df_test.fillna(mode_values)\n    \n    # Return the filled DataFrames\n    return df_train_filled, df_test_filled\n\n# Apply the function\ndf_train, df_test = fill_missing_with_mode(df_train, df_test)\n\n# Print the results\nprint(\"\\nTraining Data after filling missing values with mode:\")\nprint(df_train)\nprint(\"\\nTesting Data after filling missing values with mode:\")\nprint(df_test)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:28:30.531886Z","iopub.execute_input":"2024-08-01T10:28:30.532216Z","iopub.status.idle":"2024-08-01T10:28:47.137984Z","shell.execute_reply.started":"2024-08-01T10:28:30.532191Z","shell.execute_reply":"2024-08-01T10:28:47.136142Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Mode values from training data:\nid                         0\nclass                      p\ncap-diameter            1.49\ncap-shape                  x\ncap-surface                t\ncap-color                  n\ndoes-bruise-or-bleed       f\ngill-attachment            a\ngill-spacing               c\ngill-color                 w\nstem-height             5.24\nstem-width              2.41\nstem-color                 w\nhas-ring                   f\nring-type                  f\nhabitat                    d\nseason                     a\nName: 0, dtype: object\n\nTraining Data after filling missing values with mode:\n              id class  cap-diameter cap-shape cap-surface cap-color  \\\n0              0     e          8.80         f           s         u   \n1              1     p          4.51         x           h         o   \n2              2     e          6.94         f           s         b   \n3              3     e          3.88         f           y         g   \n4              4     e          5.85         x           l         w   \n...          ...   ...           ...       ...         ...       ...   \n3116940  3116940     e          9.29         f           t         n   \n3116941  3116941     e         10.88         s           t         w   \n3116942  3116942     p          7.82         x           e         e   \n3116943  3116943     e          9.45         p           i         n   \n3116944  3116944     p          3.20         x           s         g   \n\n        does-bruise-or-bleed gill-attachment gill-spacing gill-color  \\\n0                          f               a            c          w   \n1                          f               a            c          n   \n2                          f               x            c          w   \n3                          f               s            c          g   \n4                          f               d            c          w   \n...                      ...             ...          ...        ...   \n3116940                    t               a            c          w   \n3116941                    t               d            c          p   \n3116942                    f               a            c          w   \n3116943                    t               e            c          p   \n3116944                    f               d            c          w   \n\n         stem-height  stem-width stem-color has-ring ring-type habitat season  \n0               4.51       15.39          w        f         f       d      a  \n1               4.79        6.48          o        t         z       d      w  \n2               6.85        9.93          n        f         f       l      w  \n3               4.16        6.53          w        f         f       d      u  \n4               3.37        8.36          w        f         f       g      a  \n...              ...         ...        ...      ...       ...     ...    ...  \n3116940        12.14       18.81          w        t         g       d      u  \n3116941         6.65       26.97          w        f         f       d      u  \n3116942         9.51       11.06          y        t         z       d      a  \n3116943         9.13       17.77          w        t         p       d      u  \n3116944         2.82        7.79          w        f         f       g      u  \n\n[3116945 rows x 17 columns]\n\nTesting Data after filling missing values with mode:\n              id  cap-diameter cap-shape cap-surface cap-color  \\\n0        3116945          8.64         x           t         n   \n1        3116946          6.90         o           t         o   \n2        3116947          2.00         b           g         n   \n3        3116948          3.47         x           t         n   \n4        3116949          6.17         x           h         y   \n...          ...           ...       ...         ...       ...   \n2077959  5194904          0.88         x           g         w   \n2077960  5194905          3.12         x           s         w   \n2077961  5194906          5.73         x           e         e   \n2077962  5194907          5.03         b           g         n   \n2077963  5194908         15.51         f           t         w   \n\n        does-bruise-or-bleed gill-attachment gill-spacing gill-color  \\\n0                          t               a            c          w   \n1                          f               a            c          y   \n2                          f               a            c          n   \n3                          f               s            c          n   \n4                          f               p            c          y   \n...                      ...             ...          ...        ...   \n2077959                    f               a            d          w   \n2077960                    f               d            c          w   \n2077961                    f               a            c          w   \n2077962                    f               a            d          g   \n2077963                    f               d            c          y   \n\n         stem-height  stem-width stem-color has-ring ring-type habitat season  \n0              11.13       17.12          w        t         g       d      a  \n1               1.27       10.75          n        f         f       d      a  \n2               6.18        3.14          n        f         f       d      s  \n3               4.98        8.51          w        t         z       d      u  \n4               6.73       13.70          y        t         f       d      u  \n...              ...         ...        ...      ...       ...     ...    ...  \n2077959         2.67        1.35          e        f         f       d      u  \n2077960         2.69        7.38          w        f         f       g      a  \n2077961         6.16        9.74          y        t         z       d      a  \n2077962         6.00        3.46          g        f         f       d      a  \n2077963         2.69       17.71          w        f         f       d      w  \n\n[2077964 rows x 16 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train.tail(20)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:28:47.139560Z","iopub.execute_input":"2024-08-01T10:28:47.139834Z","iopub.status.idle":"2024-08-01T10:28:47.169706Z","shell.execute_reply.started":"2024-08-01T10:28:47.139811Z","shell.execute_reply":"2024-08-01T10:28:47.168707Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"              id class  cap-diameter cap-shape cap-surface cap-color  \\\n3116925  3116925     p          7.65         f           h         r   \n3116926  3116926     e          8.74         x           t         n   \n3116927  3116927     e          3.75         x           t         n   \n3116928  3116928     p          7.36         x           e         n   \n3116929  3116929     e          7.17         x           t         y   \n3116930  3116930     e          4.68         x           h         n   \n3116931  3116931     e          6.19         x           t         y   \n3116932  3116932     e          4.03         x           t         w   \n3116933  3116933     e          8.44         f           s         w   \n3116934  3116934     p          7.52         b           y         n   \n3116935  3116935     p         14.58         x           d         n   \n3116936  3116936     p          1.70         x           k         n   \n3116937  3116937     p          0.69         x           g         o   \n3116938  3116938     p          9.08         s           t         p   \n3116939  3116939     p          9.30         o           t         e   \n3116940  3116940     e          9.29         f           t         n   \n3116941  3116941     e         10.88         s           t         w   \n3116942  3116942     p          7.82         x           e         e   \n3116943  3116943     e          9.45         p           i         n   \n3116944  3116944     p          3.20         x           s         g   \n\n        does-bruise-or-bleed gill-attachment gill-spacing gill-color  \\\n3116925                    f               a            c          w   \n3116926                    t               a            c          w   \n3116927                    f               d            c          o   \n3116928                    f               a            c          w   \n3116929                    f               p            c          y   \n3116930                    f               x            c          w   \n3116931                    f               p            c          y   \n3116932                    f               x            c          w   \n3116933                    f               s            c          w   \n3116934                    f               a            c          p   \n3116935                    f               p            c          p   \n3116936                    f               a            c          n   \n3116937                    f               a            c          y   \n3116938                    t               d            c          p   \n3116939                    f               f            f          f   \n3116940                    t               a            c          w   \n3116941                    t               d            c          p   \n3116942                    f               a            c          w   \n3116943                    t               e            c          p   \n3116944                    f               d            c          w   \n\n         stem-height  stem-width stem-color has-ring ring-type habitat season  \n3116925         8.41       14.64          w        t         p       d      a  \n3116926         7.79       14.90          w        t         g       d      a  \n3116927         6.08        7.37          o        f         f       d      a  \n3116928         7.80        9.65          e        f         f       d      u  \n3116929         6.91       14.04          y        t         f       d      a  \n3116930         4.51        4.61          n        t         r       d      w  \n3116931         6.93       13.84          y        t         f       d      u  \n3116932         7.81        8.19          n        t         f       g      s  \n3116933         6.82       26.42          w        f         f       m      s  \n3116934        15.32       18.82          w        f         f       d      a  \n3116935        14.78       35.76          w        f         f       d      a  \n3116936         4.77        1.61          n        f         f       d      w  \n3116937         3.51        0.73          y        f         f       d      u  \n3116938         8.07       14.70          p        t         f       d      a  \n3116939         3.42       25.38          n        f         f       d      u  \n3116940        12.14       18.81          w        t         g       d      u  \n3116941         6.65       26.97          w        f         f       d      u  \n3116942         9.51       11.06          y        t         z       d      a  \n3116943         9.13       17.77          w        t         p       d      u  \n3116944         2.82        7.79          w        f         f       g      u  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>class</th>\n      <th>cap-diameter</th>\n      <th>cap-shape</th>\n      <th>cap-surface</th>\n      <th>cap-color</th>\n      <th>does-bruise-or-bleed</th>\n      <th>gill-attachment</th>\n      <th>gill-spacing</th>\n      <th>gill-color</th>\n      <th>stem-height</th>\n      <th>stem-width</th>\n      <th>stem-color</th>\n      <th>has-ring</th>\n      <th>ring-type</th>\n      <th>habitat</th>\n      <th>season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3116925</th>\n      <td>3116925</td>\n      <td>p</td>\n      <td>7.65</td>\n      <td>f</td>\n      <td>h</td>\n      <td>r</td>\n      <td>f</td>\n      <td>a</td>\n      <td>c</td>\n      <td>w</td>\n      <td>8.41</td>\n      <td>14.64</td>\n      <td>w</td>\n      <td>t</td>\n      <td>p</td>\n      <td>d</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>3116926</th>\n      <td>3116926</td>\n      <td>e</td>\n      <td>8.74</td>\n      <td>x</td>\n      <td>t</td>\n      <td>n</td>\n      <td>t</td>\n      <td>a</td>\n      <td>c</td>\n      <td>w</td>\n      <td>7.79</td>\n      <td>14.90</td>\n      <td>w</td>\n      <td>t</td>\n      <td>g</td>\n      <td>d</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>3116927</th>\n      <td>3116927</td>\n      <td>e</td>\n      <td>3.75</td>\n      <td>x</td>\n      <td>t</td>\n      <td>n</td>\n      <td>f</td>\n      <td>d</td>\n      <td>c</td>\n      <td>o</td>\n      <td>6.08</td>\n      <td>7.37</td>\n      <td>o</td>\n      <td>f</td>\n      <td>f</td>\n      <td>d</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>3116928</th>\n      <td>3116928</td>\n      <td>p</td>\n      <td>7.36</td>\n      <td>x</td>\n      <td>e</td>\n      <td>n</td>\n      <td>f</td>\n      <td>a</td>\n      <td>c</td>\n      <td>w</td>\n      <td>7.80</td>\n      <td>9.65</td>\n      <td>e</td>\n      <td>f</td>\n      <td>f</td>\n      <td>d</td>\n      <td>u</td>\n    </tr>\n    <tr>\n      <th>3116929</th>\n      <td>3116929</td>\n      <td>e</td>\n      <td>7.17</td>\n      <td>x</td>\n      <td>t</td>\n      <td>y</td>\n      <td>f</td>\n      <td>p</td>\n      <td>c</td>\n      <td>y</td>\n      <td>6.91</td>\n      <td>14.04</td>\n      <td>y</td>\n      <td>t</td>\n      <td>f</td>\n      <td>d</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>3116930</th>\n      <td>3116930</td>\n      <td>e</td>\n      <td>4.68</td>\n      <td>x</td>\n      <td>h</td>\n      <td>n</td>\n      <td>f</td>\n      <td>x</td>\n      <td>c</td>\n      <td>w</td>\n      <td>4.51</td>\n      <td>4.61</td>\n      <td>n</td>\n      <td>t</td>\n      <td>r</td>\n      <td>d</td>\n      <td>w</td>\n    </tr>\n    <tr>\n      <th>3116931</th>\n      <td>3116931</td>\n      <td>e</td>\n      <td>6.19</td>\n      <td>x</td>\n      <td>t</td>\n      <td>y</td>\n      <td>f</td>\n      <td>p</td>\n      <td>c</td>\n      <td>y</td>\n      <td>6.93</td>\n      <td>13.84</td>\n      <td>y</td>\n      <td>t</td>\n      <td>f</td>\n      <td>d</td>\n      <td>u</td>\n    </tr>\n    <tr>\n      <th>3116932</th>\n      <td>3116932</td>\n      <td>e</td>\n      <td>4.03</td>\n      <td>x</td>\n      <td>t</td>\n      <td>w</td>\n      <td>f</td>\n      <td>x</td>\n      <td>c</td>\n      <td>w</td>\n      <td>7.81</td>\n      <td>8.19</td>\n      <td>n</td>\n      <td>t</td>\n      <td>f</td>\n      <td>g</td>\n      <td>s</td>\n    </tr>\n    <tr>\n      <th>3116933</th>\n      <td>3116933</td>\n      <td>e</td>\n      <td>8.44</td>\n      <td>f</td>\n      <td>s</td>\n      <td>w</td>\n      <td>f</td>\n      <td>s</td>\n      <td>c</td>\n      <td>w</td>\n      <td>6.82</td>\n      <td>26.42</td>\n      <td>w</td>\n      <td>f</td>\n      <td>f</td>\n      <td>m</td>\n      <td>s</td>\n    </tr>\n    <tr>\n      <th>3116934</th>\n      <td>3116934</td>\n      <td>p</td>\n      <td>7.52</td>\n      <td>b</td>\n      <td>y</td>\n      <td>n</td>\n      <td>f</td>\n      <td>a</td>\n      <td>c</td>\n      <td>p</td>\n      <td>15.32</td>\n      <td>18.82</td>\n      <td>w</td>\n      <td>f</td>\n      <td>f</td>\n      <td>d</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>3116935</th>\n      <td>3116935</td>\n      <td>p</td>\n      <td>14.58</td>\n      <td>x</td>\n      <td>d</td>\n      <td>n</td>\n      <td>f</td>\n      <td>p</td>\n      <td>c</td>\n      <td>p</td>\n      <td>14.78</td>\n      <td>35.76</td>\n      <td>w</td>\n      <td>f</td>\n      <td>f</td>\n      <td>d</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>3116936</th>\n      <td>3116936</td>\n      <td>p</td>\n      <td>1.70</td>\n      <td>x</td>\n      <td>k</td>\n      <td>n</td>\n      <td>f</td>\n      <td>a</td>\n      <td>c</td>\n      <td>n</td>\n      <td>4.77</td>\n      <td>1.61</td>\n      <td>n</td>\n      <td>f</td>\n      <td>f</td>\n      <td>d</td>\n      <td>w</td>\n    </tr>\n    <tr>\n      <th>3116937</th>\n      <td>3116937</td>\n      <td>p</td>\n      <td>0.69</td>\n      <td>x</td>\n      <td>g</td>\n      <td>o</td>\n      <td>f</td>\n      <td>a</td>\n      <td>c</td>\n      <td>y</td>\n      <td>3.51</td>\n      <td>0.73</td>\n      <td>y</td>\n      <td>f</td>\n      <td>f</td>\n      <td>d</td>\n      <td>u</td>\n    </tr>\n    <tr>\n      <th>3116938</th>\n      <td>3116938</td>\n      <td>p</td>\n      <td>9.08</td>\n      <td>s</td>\n      <td>t</td>\n      <td>p</td>\n      <td>t</td>\n      <td>d</td>\n      <td>c</td>\n      <td>p</td>\n      <td>8.07</td>\n      <td>14.70</td>\n      <td>p</td>\n      <td>t</td>\n      <td>f</td>\n      <td>d</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>3116939</th>\n      <td>3116939</td>\n      <td>p</td>\n      <td>9.30</td>\n      <td>o</td>\n      <td>t</td>\n      <td>e</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>f</td>\n      <td>3.42</td>\n      <td>25.38</td>\n      <td>n</td>\n      <td>f</td>\n      <td>f</td>\n      <td>d</td>\n      <td>u</td>\n    </tr>\n    <tr>\n      <th>3116940</th>\n      <td>3116940</td>\n      <td>e</td>\n      <td>9.29</td>\n      <td>f</td>\n      <td>t</td>\n      <td>n</td>\n      <td>t</td>\n      <td>a</td>\n      <td>c</td>\n      <td>w</td>\n      <td>12.14</td>\n      <td>18.81</td>\n      <td>w</td>\n      <td>t</td>\n      <td>g</td>\n      <td>d</td>\n      <td>u</td>\n    </tr>\n    <tr>\n      <th>3116941</th>\n      <td>3116941</td>\n      <td>e</td>\n      <td>10.88</td>\n      <td>s</td>\n      <td>t</td>\n      <td>w</td>\n      <td>t</td>\n      <td>d</td>\n      <td>c</td>\n      <td>p</td>\n      <td>6.65</td>\n      <td>26.97</td>\n      <td>w</td>\n      <td>f</td>\n      <td>f</td>\n      <td>d</td>\n      <td>u</td>\n    </tr>\n    <tr>\n      <th>3116942</th>\n      <td>3116942</td>\n      <td>p</td>\n      <td>7.82</td>\n      <td>x</td>\n      <td>e</td>\n      <td>e</td>\n      <td>f</td>\n      <td>a</td>\n      <td>c</td>\n      <td>w</td>\n      <td>9.51</td>\n      <td>11.06</td>\n      <td>y</td>\n      <td>t</td>\n      <td>z</td>\n      <td>d</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>3116943</th>\n      <td>3116943</td>\n      <td>e</td>\n      <td>9.45</td>\n      <td>p</td>\n      <td>i</td>\n      <td>n</td>\n      <td>t</td>\n      <td>e</td>\n      <td>c</td>\n      <td>p</td>\n      <td>9.13</td>\n      <td>17.77</td>\n      <td>w</td>\n      <td>t</td>\n      <td>p</td>\n      <td>d</td>\n      <td>u</td>\n    </tr>\n    <tr>\n      <th>3116944</th>\n      <td>3116944</td>\n      <td>p</td>\n      <td>3.20</td>\n      <td>x</td>\n      <td>s</td>\n      <td>g</td>\n      <td>f</td>\n      <td>d</td>\n      <td>c</td>\n      <td>w</td>\n      <td>2.82</td>\n      <td>7.79</td>\n      <td>w</td>\n      <td>f</td>\n      <td>f</td>\n      <td>g</td>\n      <td>u</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Example of Label Encoding\nlabel_encoders = {}\nfor column in df_train.columns:\n    le = LabelEncoder()\n    df_train[column] = le.fit_transform(df_train[column])\n    label_encoders[column] = le\n\nprint(\"Encoded DataFrame:\")\nprint(df_train)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:28:47.171173Z","iopub.execute_input":"2024-08-01T10:28:47.171977Z","iopub.status.idle":"2024-08-01T10:28:57.500656Z","shell.execute_reply.started":"2024-08-01T10:28:47.171938Z","shell.execute_reply":"2024-08-01T10:28:57.499719Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Encoded DataFrame:\n              id  class  cap-diameter  cap-shape  cap-surface  cap-color  \\\n0              0      0           843         53           72         72   \n1              1      1           414         71           56         64   \n2              2      0           657         53           72         49   \n3              3      0           351         53           81         57   \n4              4      0           548         71           65         74   \n...          ...    ...           ...        ...          ...        ...   \n3116940  3116940      0           892         53           76         63   \n3116941  3116941      0          1051         67           76         74   \n3116942  3116942      1           745         71           53         55   \n3116943  3116943      0           908         64           59         63   \n3116944  3116944      1           283         71           72         57   \n\n         does-bruise-or-bleed  gill-attachment  gill-spacing  gill-color  \\\n0                           8               44            28          59   \n1                           8               44            28          46   \n2                           8               75            28          59   \n3                           8               70            28          37   \n4                           8               47            28          59   \n...                       ...              ...           ...         ...   \n3116940                    20               44            28          59   \n3116941                    20               47            28          48   \n3116942                     8               44            28          59   \n3116943                    20               52            28          48   \n3116944                     8               47            28          59   \n\n         stem-height  stem-width  stem-color  has-ring  ring-type  habitat  \\\n0                353        1493          55         5         18       25   \n1                381         602          47        18         39       25   \n2                587         947          46         5         18       36   \n3                318         607          55         5         18       25   \n4                239         790          55         5         18       29   \n...              ...         ...         ...       ...        ...      ...   \n3116940         1116        1835          55        18         19       25   \n3116941          567        2651          55         5         18       25   \n3116942          853        1060          57        18         39       25   \n3116943          815        1731          55        18         27       25   \n3116944          184         733          55         5         18       29   \n\n         season  \n0             0  \n1             3  \n2             3  \n3             2  \n4             0  \n...         ...  \n3116940       2  \n3116941       2  \n3116942       0  \n3116943       2  \n3116944       2  \n\n[3116945 rows x 17 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Example of Label Encoding\nlabel_encoders = {}\nfor column in df_test.columns:\n    le = LabelEncoder()\n    df_test[column] = le.fit_transform(df_test[column])\n    label_encoders[column] = le\n\nprint(\"Encoded DataFrame:\")\nprint(df_test)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:28:57.501759Z","iopub.execute_input":"2024-08-01T10:28:57.502093Z","iopub.status.idle":"2024-08-01T10:29:04.064042Z","shell.execute_reply.started":"2024-08-01T10:28:57.502044Z","shell.execute_reply":"2024-08-01T10:29:04.063107Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Encoded DataFrame:\n              id  cap-diameter  cap-shape  cap-surface  cap-color  \\\n0              0           824         59           53         44   \n1              1           650         50           53         45   \n2              2           160         36           38         44   \n3              3           307         59           53         44   \n4              4           577         59           39         55   \n...          ...           ...        ...          ...        ...   \n2077959  2077959            48         59           38         53   \n2077960  2077960           272         59           50         53   \n2077961  2077961           533         59           36         34   \n2077962  2077962           463         36           38         44   \n2077963  2077963          1511         41           53         53   \n\n         does-bruise-or-bleed  gill-attachment  gill-spacing  gill-color  \\\n0                          18               37            17          52   \n1                           5               37            17          54   \n2                           5               37            17          41   \n3                           5               57            17          41   \n4                           5               55            17          54   \n...                       ...              ...           ...         ...   \n2077959                     5               37            18          52   \n2077960                     5               41            17          52   \n2077961                     5               37            17          52   \n2077962                     5               37            18          31   \n2077963                     5               41            17          54   \n\n         stem-height  stem-width  stem-color  has-ring  ring-type  habitat  \\\n0               1009        1669          51        17         15       16   \n1                 23        1032          38         6         14       16   \n2                514         271          38         6         14       16   \n3                394         808          51        17         35       16   \n4                569        1327          53        17         14       16   \n...              ...         ...         ...       ...        ...      ...   \n2077959          163          92          29         6         14       16   \n2077960          165         695          51         6         14       19   \n2077961          512         931          53        17         35       16   \n2077962          496         303          31         6         14       16   \n2077963          165        1728          51         6         14       16   \n\n         season  \n0             0  \n1             0  \n2             1  \n3             2  \n4             2  \n...         ...  \n2077959       2  \n2077960       0  \n2077961       0  \n2077962       0  \n2077963       3  \n\n[2077964 rows x 16 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:29:04.065598Z","iopub.execute_input":"2024-08-01T10:29:04.066287Z","iopub.status.idle":"2024-08-01T10:29:04.072709Z","shell.execute_reply.started":"2024-08-01T10:29:04.066247Z","shell.execute_reply":"2024-08-01T10:29:04.071737Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(3116945, 17)"},"metadata":{}}]},{"cell_type":"code","source":"df_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:29:04.074191Z","iopub.execute_input":"2024-08-01T10:29:04.074838Z","iopub.status.idle":"2024-08-01T10:29:04.082967Z","shell.execute_reply.started":"2024-08-01T10:29:04.074802Z","shell.execute_reply":"2024-08-01T10:29:04.082170Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(2077964, 16)"},"metadata":{}}]},{"cell_type":"code","source":"#Checking If training data is Imbalanced\nresponse_data = df_train['class'].value_counts()\nplt.figure(figsize=(6,6))\nfig, ax = plt.subplots()\nax.pie(response_data, labels = [0,1])\nax.set_title('Checking Imbalance in Training Data Or Response')","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:29:04.084210Z","iopub.execute_input":"2024-08-01T10:29:04.084553Z","iopub.status.idle":"2024-08-01T10:29:04.251612Z","shell.execute_reply.started":"2024-08-01T10:29:04.084512Z","shell.execute_reply":"2024-08-01T10:29:04.250207Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"Text(0.5, 1.0, 'Checking Imbalance in Training Data Or Response')"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 600x600 with 0 Axes>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"df_train.columns","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:29:04.253362Z","iopub.execute_input":"2024-08-01T10:29:04.254615Z","iopub.status.idle":"2024-08-01T10:29:04.262864Z","shell.execute_reply.started":"2024-08-01T10:29:04.254568Z","shell.execute_reply":"2024-08-01T10:29:04.261501Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"Index(['id', 'class', 'cap-diameter', 'cap-shape', 'cap-surface', 'cap-color',\n       'does-bruise-or-bleed', 'gill-attachment', 'gill-spacing', 'gill-color',\n       'stem-height', 'stem-width', 'stem-color', 'has-ring', 'ring-type',\n       'habitat', 'season'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"X_train_original = df_train[['cap-diameter', 'cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', 'gill-spacing', 'gill-color', 'stem-height','stem-width', 'stem-color', 'has-ring','ring-type','habitat','season']]\ny_train_original = df_train['class']","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:29:04.264629Z","iopub.execute_input":"2024-08-01T10:29:04.265487Z","iopub.status.idle":"2024-08-01T10:29:04.484159Z","shell.execute_reply.started":"2024-08-01T10:29:04.265442Z","shell.execute_reply":"2024-08-01T10:29:04.483345Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"X_preds = df_test[['cap-diameter', 'cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', 'gill-spacing', 'gill-color', 'stem-height','stem-width', 'stem-color', 'has-ring','ring-type','habitat','season']]","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:29:04.485277Z","iopub.execute_input":"2024-08-01T10:29:04.485566Z","iopub.status.idle":"2024-08-01T10:29:04.615438Z","shell.execute_reply.started":"2024-08-01T10:29:04.485542Z","shell.execute_reply":"2024-08-01T10:29:04.614601Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"X_preds = X_preds.to_numpy()\nX_preds_tensor = torch.tensor(X_preds, dtype = torch.float32)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:50:49.105686Z","iopub.execute_input":"2024-08-01T10:50:49.106550Z","iopub.status.idle":"2024-08-01T10:50:49.261419Z","shell.execute_reply.started":"2024-08-01T10:50:49.106518Z","shell.execute_reply":"2024-08-01T10:50:49.260507Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_train_original, y_train_original, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:29:04.616610Z","iopub.execute_input":"2024-08-01T10:29:04.616910Z","iopub.status.idle":"2024-08-01T10:29:05.772243Z","shell.execute_reply.started":"2024-08-01T10:29:04.616885Z","shell.execute_reply":"2024-08-01T10:29:05.771217Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:29:05.773859Z","iopub.execute_input":"2024-08-01T10:29:05.774265Z","iopub.status.idle":"2024-08-01T10:29:05.780031Z","shell.execute_reply.started":"2024-08-01T10:29:05.774229Z","shell.execute_reply":"2024-08-01T10:29:05.779026Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"(2493556, 15) (2493556,) (623389, 15) (623389,)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(X_preds.shape)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:29:05.781252Z","iopub.execute_input":"2024-08-01T10:29:05.781576Z","iopub.status.idle":"2024-08-01T10:29:05.791280Z","shell.execute_reply.started":"2024-08-01T10:29:05.781551Z","shell.execute_reply":"2024-08-01T10:29:05.790313Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"(2077964, 15)\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train = X_train.to_numpy()\ny_train = y_train.to_numpy()\nX_test = X_test.to_numpy()\ny_test = y_test.to_numpy()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:29:05.793853Z","iopub.execute_input":"2024-08-01T10:29:05.794154Z","iopub.status.idle":"2024-08-01T10:29:05.932394Z","shell.execute_reply.started":"2024-08-01T10:29:05.794130Z","shell.execute_reply":"2024-08-01T10:29:05.931300Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"X_train_tensor = torch.tensor(X_train, dtype = torch.float32)\ny_train_tensor = torch.tensor(y_train, dtype = torch.float32)\nX_test_tensor = torch.tensor(X_test, dtype = torch.float32)\ny_test_tensor = torch.tensor(y_test, dtype = torch.float32)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:29:05.933672Z","iopub.execute_input":"2024-08-01T10:29:05.933996Z","iopub.status.idle":"2024-08-01T10:29:05.977031Z","shell.execute_reply.started":"2024-08-01T10:29:05.933969Z","shell.execute_reply":"2024-08-01T10:29:05.976189Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Custom dataset class\nclass CustomDataset(Dataset):\n    def __init__(self, X, y=None):\n        self.X = X\n        self.y = y\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        \n        try:\n            if self.y is not None:\n                return self.X[idx], self.y[idx]\n            else:\n                return self.X[idx]\n        except Exception as e:\n            print(f\"Exception in __getitem__: {e}\")\n            raise","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:29:05.978308Z","iopub.execute_input":"2024-08-01T10:29:05.978691Z","iopub.status.idle":"2024-08-01T10:29:05.985711Z","shell.execute_reply.started":"2024-08-01T10:29:05.978656Z","shell.execute_reply":"2024-08-01T10:29:05.984647Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"train_dataset = CustomDataset(X_train_tensor, y_train_tensor)\ntest_dataset = CustomDataset(X_test_tensor, y_test_tensor)\n\n# Create DataLoaders\n# train_loader = DataLoader(train_dataset, batch_size=64,shuffle=True,pin_memory=True)\n# test_loader = DataLoader(test_dataset, batch_size=64,shuffle=False, pin_memory=True)\ntrain_loader = DataLoader(train_dataset, batch_size=128,shuffle=True,num_workers=3, pin_memory=True, persistent_workers=True)\ntest_loader = DataLoader(test_dataset, batch_size=128,shuffle=False,num_workers=3, pin_memory=True, persistent_workers=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:29:05.986900Z","iopub.execute_input":"2024-08-01T10:29:05.987246Z","iopub.status.idle":"2024-08-01T10:29:05.995775Z","shell.execute_reply.started":"2024-08-01T10:29:05.987221Z","shell.execute_reply":"2024-08-01T10:29:05.994874Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Model\nclass ModelV1(nn.Module):\n    def __init__(self,\n                 input_shape: int,\n                 hidden_units: int,\n                 output_shapes: int):\n        super().__init__()\n\n        self.layer_stack = nn.Sequential(\n            nn.Linear(in_features=input_shape, out_features=hidden_units),\n            nn.ReLU(),\n            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n            nn.ELU(),\n            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n            nn.ReLU(),\n            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n            nn.ELU(),\n            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n            nn.ReLU(),\n            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n            nn.ELU(),\n            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n            nn.ReLU(),\n            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n            nn.ELU(),\n            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n            nn.ReLU(),\n            nn.Linear(in_features=hidden_units, out_features=output_shapes)\n        )\n\n    def forward(self, x: torch.Tensor):\n        return self.layer_stack(x)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:29:05.996804Z","iopub.execute_input":"2024-08-01T10:29:05.997103Z","iopub.status.idle":"2024-08-01T10:29:06.008954Z","shell.execute_reply.started":"2024-08-01T10:29:05.997053Z","shell.execute_reply":"2024-08-01T10:29:06.008119Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"model_1 = ModelV1(input_shape=15,\n                  hidden_units=512,\n                  output_shapes=1).to(device)\n\n\nloss_fn = nn.BCEWithLogitsLoss()\n\noptimizer = torch.optim.SGD(params=model_1.parameters(),\n                            lr=0.1)\n# optimizer = torch.optim.SGD(params=model_1.parameters(),\n#                             lr=0.001)\n\n\n\n# Define a ReduceLROnPlateau scheduler\n# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=1)\nscheduler = CosineAnnealingLR(optimizer, T_max=10, eta_min=0.001)\n\n\n\ndef accuracy_fn(y_true, y_pred):\n    correct = torch.eq(y_true, y_pred).sum().item()\n    acc = (correct/len(y_pred))*100\n    return acc","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:29:06.013619Z","iopub.execute_input":"2024-08-01T10:29:06.013927Z","iopub.status.idle":"2024-08-01T10:29:06.956193Z","shell.execute_reply.started":"2024-08-01T10:29:06.013903Z","shell.execute_reply":"2024-08-01T10:29:06.955335Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.cuda.amp import GradScaler, autocast\n\n# Initialize the GradScaler\nscaler = GradScaler()\n\nepochs = 11\n\nfor epoch in range(epochs):\n    current_lr = optimizer.param_groups[0]['lr']\n\n    if epoch % 1 == 0:\n        print(f\"\\n\\n\\nEpoch: {epoch}\")\n\n    ### TRAINING\n    model_1.train()\n    train_loss = 0\n\n    # Loop through training batches\n    for batch, (X, y) in enumerate(train_loader):\n        X, y = X.to(device), y.to(device)\n\n        # 1. Forward pass with autocast\n        with autocast():\n            y_logits = model_1(X).squeeze()\n            y_pred = torch.round(torch.sigmoid(y_logits))\n            loss = loss_fn(y_logits, y)\n        \n        optimizer.zero_grad()\n        \n        # 2. Backward pass with scaling\n        scaler.scale(loss).backward()\n\n        # 3. Optimizer step\n        scaler.step(optimizer)\n        scaler.update()\n\n        train_loss += loss.item()  # Accumulate training loss\n        acc = accuracy_fn(y_true=y, y_pred=y_pred)\n        \n        if batch % 4000 == 0 and epoch % 1 == 0:\n            print(f'Looked at: {batch * 128}/{len(train_loader.dataset)} samples. | Loss: {loss:.5f} | Acc: {acc:.2f}% ')\n\n    # Average train loss\n    train_loss /= len(train_loader)\n    if epoch % 1 == 0:\n        print(f\"\\nAverage Train Loss in Epoch {epoch}: {train_loss:.4f}\")\n\n    ### EVALUATION\n    model_1.eval()  # Ensure model is in evaluation mode\n    test_loss = 0\n    test_acc = 0\n\n    with torch.no_grad():  # No need to compute gradients\n        for X, y in test_loader:\n            X, y = X.to(device), y.to(device)\n\n            # Forward pass with autocast\n            with autocast():\n                y_logits = model_1(X).squeeze()\n                y_pred = torch.round(torch.sigmoid(y_logits))\n                loss = loss_fn(y_logits, y)\n\n            test_loss += loss.item()  # Accumulate test loss\n            acc = accuracy_fn(y_true=y, y_pred=y_pred)\n            test_acc += acc\n\n    # Scheduler step\n    scheduler.step()\n\n    # Print learning rate\n    \n\n    # Average test loss and accuracy\n    test_loss /= len(test_loader)\n    test_acc /= len(test_loader)\n    print(f\"\\nAverage Test Loss in Epoch {epoch}: {test_loss:.4f} | Test Accuracy: {test_acc:.2f}% | Current lr: {current_lr}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:29:06.957384Z","iopub.execute_input":"2024-08-01T10:29:06.957951Z","iopub.status.idle":"2024-08-01T10:48:32.817968Z","shell.execute_reply.started":"2024-08-01T10:29:06.957912Z","shell.execute_reply":"2024-08-01T10:48:32.816715Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"\n\n\nEpoch: 0\nLooked at: 0/2493556 samples. | Loss: 0.68801 | Acc: 59.38% \nLooked at: 512000/2493556 samples. | Loss: 0.45750 | Acc: 78.91% \nLooked at: 1024000/2493556 samples. | Loss: 0.30438 | Acc: 88.28% \nLooked at: 1536000/2493556 samples. | Loss: 0.30727 | Acc: 86.72% \nLooked at: 2048000/2493556 samples. | Loss: 0.31360 | Acc: 86.72% \n\nAverage Train Loss in Epoch 0: 0.3720\n\nAverage Test Loss in Epoch 0: 0.2802 | Test Accuracy: 87.94% | Current lr: 0.1\n\n\n\nEpoch: 1\nLooked at: 0/2493556 samples. | Loss: 0.35661 | Acc: 83.59% \nLooked at: 512000/2493556 samples. | Loss: 0.21705 | Acc: 90.62% \nLooked at: 1024000/2493556 samples. | Loss: 0.21479 | Acc: 89.84% \nLooked at: 1536000/2493556 samples. | Loss: 0.37301 | Acc: 85.94% \nLooked at: 2048000/2493556 samples. | Loss: 0.41003 | Acc: 84.38% \n\nAverage Train Loss in Epoch 1: 0.2114\n\nAverage Test Loss in Epoch 1: 0.2138 | Test Accuracy: 91.47% | Current lr: 0.09757729755661011\n\n\n\nEpoch: 2\nLooked at: 0/2493556 samples. | Loss: 0.25262 | Acc: 86.72% \nLooked at: 512000/2493556 samples. | Loss: 0.23621 | Acc: 92.97% \nLooked at: 1024000/2493556 samples. | Loss: 0.16850 | Acc: 92.97% \nLooked at: 1536000/2493556 samples. | Loss: 0.07173 | Acc: 97.66% \nLooked at: 2048000/2493556 samples. | Loss: 0.20166 | Acc: 93.75% \n\nAverage Train Loss in Epoch 2: 0.1541\n\nAverage Test Loss in Epoch 2: 0.1020 | Test Accuracy: 96.66% | Current lr: 0.0905463412215599\n\n\n\nEpoch: 3\nLooked at: 0/2493556 samples. | Loss: 0.05348 | Acc: 98.44% \nLooked at: 512000/2493556 samples. | Loss: 0.13375 | Acc: 94.53% \nLooked at: 1024000/2493556 samples. | Loss: 0.08739 | Acc: 97.66% \nLooked at: 1536000/2493556 samples. | Loss: 0.13706 | Acc: 95.31% \nLooked at: 2048000/2493556 samples. | Loss: 0.16904 | Acc: 93.75% \n\nAverage Train Loss in Epoch 3: 0.1198\n\nAverage Test Loss in Epoch 3: 0.1010 | Test Accuracy: 96.66% | Current lr: 0.07959536998847742\n\n\n\nEpoch: 4\nLooked at: 0/2493556 samples. | Loss: 0.06984 | Acc: 96.88% \nLooked at: 512000/2493556 samples. | Loss: 0.11470 | Acc: 95.31% \nLooked at: 1024000/2493556 samples. | Loss: 0.10196 | Acc: 96.88% \nLooked at: 1536000/2493556 samples. | Loss: 0.08578 | Acc: 97.66% \nLooked at: 2048000/2493556 samples. | Loss: 0.11031 | Acc: 96.88% \n\nAverage Train Loss in Epoch 4: 0.0965\n\nAverage Test Loss in Epoch 4: 0.0842 | Test Accuracy: 97.35% | Current lr: 0.0657963412215599\n\n\n\nEpoch: 5\nLooked at: 0/2493556 samples. | Loss: 0.07755 | Acc: 96.88% \nLooked at: 512000/2493556 samples. | Loss: 0.06888 | Acc: 96.88% \nLooked at: 1024000/2493556 samples. | Loss: 0.07245 | Acc: 96.09% \nLooked at: 1536000/2493556 samples. | Loss: 0.09079 | Acc: 96.09% \nLooked at: 2048000/2493556 samples. | Loss: 0.07729 | Acc: 96.88% \n\nAverage Train Loss in Epoch 5: 0.0800\n\nAverage Test Loss in Epoch 5: 0.1688 | Test Accuracy: 93.59% | Current lr: 0.0505\n\n\n\nEpoch: 6\nLooked at: 0/2493556 samples. | Loss: 0.20753 | Acc: 93.75% \nLooked at: 512000/2493556 samples. | Loss: 0.05906 | Acc: 97.66% \nLooked at: 1024000/2493556 samples. | Loss: 0.03638 | Acc: 98.44% \nLooked at: 1536000/2493556 samples. | Loss: 0.26430 | Acc: 90.62% \nLooked at: 2048000/2493556 samples. | Loss: 0.04172 | Acc: 98.44% \n\nAverage Train Loss in Epoch 6: 0.0673\n\nAverage Test Loss in Epoch 6: 0.0736 | Test Accuracy: 97.74% | Current lr: 0.03520365877844011\n\n\n\nEpoch: 7\nLooked at: 0/2493556 samples. | Loss: 0.05516 | Acc: 98.44% \nLooked at: 512000/2493556 samples. | Loss: 0.08068 | Acc: 99.22% \nLooked at: 1024000/2493556 samples. | Loss: 0.06071 | Acc: 98.44% \nLooked at: 1536000/2493556 samples. | Loss: 0.07691 | Acc: 98.44% \nLooked at: 2048000/2493556 samples. | Loss: 0.02788 | Acc: 98.44% \n\nAverage Train Loss in Epoch 7: 0.0586\n\nAverage Test Loss in Epoch 7: 0.0623 | Test Accuracy: 98.22% | Current lr: 0.02140463001152259\n\n\n\nEpoch: 8\nLooked at: 0/2493556 samples. | Loss: 0.08931 | Acc: 97.66% \nLooked at: 512000/2493556 samples. | Loss: 0.03472 | Acc: 98.44% \nLooked at: 1024000/2493556 samples. | Loss: 0.04081 | Acc: 99.22% \nLooked at: 1536000/2493556 samples. | Loss: 0.02125 | Acc: 99.22% \nLooked at: 2048000/2493556 samples. | Loss: 0.11460 | Acc: 97.66% \n\nAverage Train Loss in Epoch 8: 0.0529\n\nAverage Test Loss in Epoch 8: 0.0568 | Test Accuracy: 98.46% | Current lr: 0.010453658778440109\n\n\n\nEpoch: 9\nLooked at: 0/2493556 samples. | Loss: 0.06271 | Acc: 98.44% \nLooked at: 512000/2493556 samples. | Loss: 0.03282 | Acc: 98.44% \nLooked at: 1024000/2493556 samples. | Loss: 0.00606 | Acc: 100.00% \nLooked at: 1536000/2493556 samples. | Loss: 0.04257 | Acc: 98.44% \nLooked at: 2048000/2493556 samples. | Loss: 0.05654 | Acc: 97.66% \n\nAverage Train Loss in Epoch 9: 0.0494\n\nAverage Test Loss in Epoch 9: 0.0533 | Test Accuracy: 98.58% | Current lr: 0.0034227024433899004\n\n\n\nEpoch: 10\nLooked at: 0/2493556 samples. | Loss: 0.06629 | Acc: 98.44% \nLooked at: 512000/2493556 samples. | Loss: 0.09613 | Acc: 97.66% \nLooked at: 1024000/2493556 samples. | Loss: 0.07450 | Acc: 97.66% \nLooked at: 1536000/2493556 samples. | Loss: 0.01440 | Acc: 100.00% \nLooked at: 2048000/2493556 samples. | Loss: 0.04028 | Acc: 98.44% \n\nAverage Train Loss in Epoch 10: 0.0479\n\nAverage Test Loss in Epoch 10: 0.0526 | Test Accuracy: 98.61% | Current lr: 0.001\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f'Allocated memory: {torch.cuda.memory_allocated()} bytes')\nprint(f'Cached memory: {torch.cuda.memory_reserved()} bytes')","metadata":{"execution":{"iopub.status.busy":"2024-08-01T10:48:32.820055Z","iopub.execute_input":"2024-08-01T10:48:32.820371Z","iopub.status.idle":"2024-08-01T10:48:32.827430Z","shell.execute_reply.started":"2024-08-01T10:48:32.820343Z","shell.execute_reply":"2024-08-01T10:48:32.826414Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Allocated memory: 33925120 bytes\nCached memory: 46137344 bytes\n","output_type":"stream"}]},{"cell_type":"code","source":"# Make prediction\nmodel_1.eval()\nwith torch.inference_mode():\n    y_logits = model_1(X_preds_tensor.to(device))\n    \nprint(y_logits[:10])\ny_pred_probs = torch.sigmoid(y_logits)\ny_preds = torch.round(y_pred_probs)\nprint(y_preds[:10])","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:04:17.710120Z","iopub.execute_input":"2024-08-01T11:04:17.710461Z","iopub.status.idle":"2024-08-01T11:04:19.111019Z","shell.execute_reply.started":"2024-08-01T11:04:17.710437Z","shell.execute_reply":"2024-08-01T11:04:19.110019Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"tensor([[-3.6239],\n        [ 6.0709],\n        [ 2.4550],\n        [ 4.5167],\n        [-5.2790],\n        [-4.6508],\n        [-5.8265],\n        [ 4.0547],\n        [ 4.5527],\n        [-6.2531]], device='cuda:0')\ntensor([[0.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [0.]], device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"y_preds = y_preds.to('cpu')","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:04:22.283943Z","iopub.execute_input":"2024-08-01T11:04:22.284338Z","iopub.status.idle":"2024-08-01T11:04:22.289459Z","shell.execute_reply.started":"2024-08-01T11:04:22.284308Z","shell.execute_reply":"2024-08-01T11:04:22.288331Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"y_preds_numpy = y_preds.numpy()\ny_preds_numpy = np.array(y_preds_numpy).flatten()\ny_preds_string = ['e' if p == 0 else 'p' for p in y_preds_numpy]","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:06:13.951771Z","iopub.execute_input":"2024-08-01T11:06:13.952182Z","iopub.status.idle":"2024-08-01T11:06:20.316608Z","shell.execute_reply.started":"2024-08-01T11:06:13.952152Z","shell.execute_reply":"2024-08-01T11:06:20.315678Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"y_preds_numpy.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:06:20.318231Z","iopub.execute_input":"2024-08-01T11:06:20.318507Z","iopub.status.idle":"2024-08-01T11:06:20.324645Z","shell.execute_reply.started":"2024-08-01T11:06:20.318484Z","shell.execute_reply":"2024-08-01T11:06:20.323673Z"},"trusted":true},"execution_count":70,"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"(2077964,)"},"metadata":{}}]},{"cell_type":"code","source":"assert len(df_for_preds_id['id']) == len(y_preds_string)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:08:00.509687Z","iopub.execute_input":"2024-08-01T11:08:00.510324Z","iopub.status.idle":"2024-08-01T11:08:00.514858Z","shell.execute_reply.started":"2024-08-01T11:08:00.510291Z","shell.execute_reply":"2024-08-01T11:08:00.513896Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"df_for_preds_id['id'].shape","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:05:25.530048Z","iopub.execute_input":"2024-08-01T11:05:25.530718Z","iopub.status.idle":"2024-08-01T11:05:25.536996Z","shell.execute_reply.started":"2024-08-01T11:05:25.530684Z","shell.execute_reply":"2024-08-01T11:05:25.536116Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"(2077964,)"},"metadata":{}}]},{"cell_type":"code","source":"y_preds_string[:10]","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:08:33.915531Z","iopub.execute_input":"2024-08-01T11:08:33.915961Z","iopub.status.idle":"2024-08-01T11:08:33.922689Z","shell.execute_reply.started":"2024-08-01T11:08:33.915927Z","shell.execute_reply":"2024-08-01T11:08:33.921721Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"['e', 'p', 'p', 'p', 'e', 'e', 'e', 'p', 'p', 'e']"},"metadata":{}}]},{"cell_type":"code","source":"df_predictions = pd.DataFrame({\n    'id': df_for_preds_id['id'],\n    'class': y_preds_string\n})\n\nprint(df_predictions)\n\n# Optionally, save to CSV\ndf_predictions.to_csv('submission.csv', index=False)\nprint('Submission successful!')","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:09:43.469417Z","iopub.execute_input":"2024-08-01T11:09:43.469830Z","iopub.status.idle":"2024-08-01T11:09:46.025946Z","shell.execute_reply.started":"2024-08-01T11:09:43.469799Z","shell.execute_reply":"2024-08-01T11:09:46.025064Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"              id class\n0        3116945     e\n1        3116946     p\n2        3116947     p\n3        3116948     p\n4        3116949     e\n...          ...   ...\n2077959  5194904     p\n2077960  5194905     p\n2077961  5194906     p\n2077962  5194907     e\n2077963  5194908     e\n\n[2077964 rows x 2 columns]\nSubmission successful!\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}